{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of EDA Task 7",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "161b9ba5fe1e4a43aa093b7e9deb4e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_527f4dc76528447aa9145afa2cd9f6d0",
              "IPY_MODEL_49d6e74f3022412b9b17710171a97472",
              "IPY_MODEL_b6c9a8a382704df69ae28cf6acf97a88"
            ],
            "layout": "IPY_MODEL_22a125466ed546cf842cd0929376ebde"
          }
        },
        "527f4dc76528447aa9145afa2cd9f6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_059b0f26e11a4f5dba3d3ef894c4f1d9",
            "placeholder": "​",
            "style": "IPY_MODEL_9c841448ada4429ba778e294274d68ea",
            "value": "100%"
          }
        },
        "49d6e74f3022412b9b17710171a97472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_698a29f8a8ea4fbcb23866f0d28f3995",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_079f4028aeed4fe9aa9569e9d29436c4",
            "value": 46830571
          }
        },
        "b6c9a8a382704df69ae28cf6acf97a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a15c420b2c9409ba004a0224616e0b3",
            "placeholder": "​",
            "style": "IPY_MODEL_0b779f1bdd7b458e808815542626ad73",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 92.1MB/s]"
          }
        },
        "22a125466ed546cf842cd0929376ebde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "059b0f26e11a4f5dba3d3ef894c4f1d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c841448ada4429ba778e294274d68ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "698a29f8a8ea4fbcb23866f0d28f3995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "079f4028aeed4fe9aa9569e9d29436c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a15c420b2c9409ba004a0224616e0b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b779f1bdd7b458e808815542626ad73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kurt9806/MLCEE-Project-Task7/blob/main/EDA_Task_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NX3H5mOTFyV3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "#edit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cHUpsq6lHELy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba1a975-865a-4f42-fd16-47cd96601bdb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = np.load('/content/drive/MyDrive/Machine Learning Project/task7_X_train.npy').astype(np.uint8)\n",
        "data_test = np.load('/content/drive/MyDrive/Machine Learning Project/task7_X_test.npy').astype(np.uint8)\n",
        "y_train = np.load('/content/drive/MyDrive/Machine Learning Project/task7_y_train.npy')\n",
        "y_test = np.load('/content/drive/MyDrive/Machine Learning Project/task7_y_test.npy')\n"
      ],
      "metadata": {
        "id": "wVf_SKsaHBJ6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'train_' + str(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rjDUykeHjlVo",
        "outputId": "3e51675b-bd03-434d-b0c5-4032f876c85c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop to change each array to image\n",
        "\n",
        "for i in range(y_train.size):\n",
        "  name = 'train_' + str(i)\n"
      ],
      "metadata": {
        "id": "ICSApMCOF_Xj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "c6DsCw1LdkJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking distribution of data\n",
        "labels_train = pd.DataFrame(y_train, columns=['Heavy damage','Minor damage','Moderate damage','Undamaged'])\n",
        "labels_test = pd.DataFrame(y_test, columns=['Heavy damage','Minor damage','Moderate damage','Undamaged'])"
      ],
      "metadata": {
        "id": "G1Hv2NOlaDyv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(list(labels_train), labels_train.sum(axis=0))\n",
        "plt.bar(list(labels_test), labels_test.sum(axis=0))\n",
        "\n",
        "plt.title('Class Frequency')\n",
        "plt.xlabel('Class')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('saved_figure-300pi.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "6r1yU2coaYAM",
        "outputId": "73fb76b6-0d17-4f8f-e45c-fb8d4b874e81"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BaseLine\n"
      ],
      "metadata": {
        "id": "Jsl29TdKd6Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from sklearn import svm\n",
        "import pandas as pd\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "rv-3P3NFd688"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#If there is a GPU avaiable for computations, we want to use it (else we will use a CPU)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zIdkdvQfedI",
        "outputId": "02cf46a0-86ee-4af2-b4fe-78b4667ebf9d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        \"\"\"\n",
        "        input: \n",
        "        'cracked_images_path': This corresponds to the path of images with cracks on your PC or Google drive\n",
        "        'uncracked_images_path': This corresponds to the path of images without cracks on your PC or Google drive\n",
        "        \n",
        "        Output: None required (you don't need a return line)\n",
        "        \n",
        "        To implement: Define variables that you can use in other methods within this class. This are several ways of\n",
        "        approaching this. Suggested way is to define 5 variables: self.cracked_path, self.uncracked_path,\n",
        "        self.file_names_cracked, self.file_names_uncracked and self.preprocess\n",
        "        \n",
        "        You can obtain all filenames within a given folder using the 'glob' subroutine in python. This subroutine can\n",
        "        identify all files that have a similar looking filename.\n",
        "        \n",
        "        self.preprocess is a composition of transforms that will preprocess a given image. Implement at least these \n",
        "        transforms: (1) Resize the images to a size that the pretrained networks (ResNet18) will accept (2) Convert the image to \n",
        "        a tensor and, (3) Normalize the tensor using the mean and standard deviation of training examples used to train the ResNet network. \n",
        "        You can get these values when you look at ResNET's documentation on the Pytorch's website.\n",
        "        Refer to torchvision.transforms.compose \n",
        "        \n",
        "        You can implement additional transforms that will augment your training data like random horizontal or vertical flip\n",
        "        \"\"\"\n",
        "        #You code after this line\n",
        "        self.X = X.astype(np.uint8)\n",
        "\n",
        "        #self.X = torch.from_numpy(X.astype(np.uint8))\n",
        "\n",
        "        self.X = self.X[:,[1,2,0]]\n",
        "        self.y = torch.from_numpy(y)\n",
        "\n",
        "        # Transformations\n",
        "        self.transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "        # Combine data\n",
        "        data = []\n",
        "        N = X.shape[0]\n",
        "        for i in range(N):\n",
        "          data.append([np.argmax(self.y[i]).float(), self.X[i]])\n",
        "        \n",
        "        self.dataset = pd.DataFrame(data, columns=['Label', 'Image_array'])\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        ouput: Length of the entire dataset using the variables defined in __init__ method\n",
        "        \"\"\"\n",
        "        \n",
        "        #You code after this line\n",
        "        length_of_entire_dataset = self.dataset.shape[0]\n",
        "        \n",
        "        return length_of_entire_dataset\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        \"\"\"\n",
        "        Input: 'i': Integer. The ith example within the example set\n",
        "        \n",
        "        Output: tensor_image: Tensor of size (3,224,224) (image corresponding to the ith example).\n",
        "        For a given 'i', import image using the path, filename and the Image module (from PIL library). Then use\n",
        "        self.preprocess.\n",
        "        \n",
        "        label: Integer: '0' or '1' (0 for an uncracked image and 1 for a cracked image)\n",
        "        \"\"\"\n",
        "        #You code after this line\n",
        "        img_array = self.dataset.iloc[i, 1]\n",
        "        # Open Image \n",
        "        image = Image.fromarray(img_array)\n",
        "\n",
        "        # Extract the label\n",
        "        label = self.dataset.iloc[i,0]\n",
        "\n",
        "        # Preprocessing\n",
        "        if self.transform:\n",
        "          tensor_image = self.transform(image)\n",
        "\n",
        "        return tensor_image,label"
      ],
      "metadata": {
        "id": "zHErxHBXe6bv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Do not edit this cell\n",
        "#Here we are creating an insatance of the 'CEE498_Concrete_dataset' class you defined for the\n",
        "#Training set\n",
        "train_dataset=Dataset(data_train,y_train)\n",
        "#This line defines a dataloader that will use the the instance 'train_dataset' and combines multiple examples \n",
        "#to form a mini batch of size 'batch_size'\n",
        "train_dataloader=torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "#Here we are creating an insatance of the 'CEE498_Concrete_dataset' class you defined for the\n",
        "#Test set\n",
        "test_dataset=Dataset(data_test,y_test)\n",
        "#This line defines a dataloader that will use the the instance 'test_dataset' and combines multiple examples \n",
        "#to form a mini batch of size 'batch_size'\n",
        "test_dataloader=torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "zjZ8zQTjpAxy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def train_classifier_one_epoch(train_data_loader, model, loss_function, optimizer,device):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    train_data_loader: Dataloader defined using an instance of 'CEE498_Concrete_dataset' corresponding to the training set\n",
        "    model: Your network\n",
        "    loss_function,optimizer: self explanatory\n",
        "    device: cuda (0) or cpu\n",
        "    \n",
        "    \n",
        "    output:\n",
        "    loss_individual_epoch: scalar: average Loss accumulated over the entire dataset as training progresses over all minibatches\n",
        "    model: Your model trainged after one epoch\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    loss_individual_epoch = 0\n",
        "    for i, (images, labels) in tqdm(enumerate(train_data_loader),'Training progress within an epoch'):\n",
        "        \"\"\"\n",
        "        Fill your code after this\n",
        "        \"\"\"\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels = labels.unsqueeze(1)\n",
        "        labels = labels.float()\n",
        "        \n",
        "        # Make prediction\n",
        "        yhat = model(images)\n",
        "        #yhat = yhat.view(-1,4)\n",
        "        \n",
        "        #yhat = predict_if_crack(yhat)\n",
        "        #yhat = torch.unsqueeze(yhat,1)\n",
        "\n",
        "        #print(yhat, yhat.shape)\n",
        "        #print(labels, labels.shape)\n",
        "\n",
        "        \n",
        "        # calculate the loss\n",
        "        loss = loss_function(yhat, torch.max(labels, 1)[1])\n",
        "        # calculate the gradients\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_individual_epoch += loss.item()\n",
        "\n",
        "        \n",
        "    return loss_individual_epoch,model"
      ],
      "metadata": {
        "id": "d8BUvev0bP5w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_if_crack(output_final_layer):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "    ouput_final_layer: Numpy ouput from the network (convert the tensor into a numpy array before sending it as an input to \n",
        "    this function): Shape (N,a) where 'N' is number of examples and 'a' depends on\n",
        "    the network (either 1 or 2)\n",
        "    \n",
        "    prediction: numpy array: shape: (N,) (0 for no crack or 1 for cracked imaged)\n",
        "    \"\"\"\n",
        "    #You code after this line\n",
        "\n",
        "    _, prediction = torch.max(output_final_layer.data,1)\n",
        "\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "oykxk99-niyj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_classifier(test_dataloader, model):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        use the 'predict_if_crack' in this to help you\n",
        "        test_dataloader: Dataloader defined using an instance of 'CEE498_Concrete_dataset' corresponding to the test set\n",
        "        model: Trained network to be tested\n",
        "        \n",
        "        Ouput: No return statement required\n",
        "        \"\"\"\n",
        "        y_true = []\n",
        "        y_predict = []\n",
        "        for i, (images, labels) in tqdm(enumerate(test_dataloader),desc='Test progress'):\n",
        "            #You code after this line\n",
        "\n",
        "            # images = images.cuda()\n",
        "            # labels = labels.cuda()\n",
        "\n",
        "            #predict = model(images)\n",
        "            #predict = predict.round()\n",
        "            #predict = torch.max(predict.data,1)\n",
        "            # predict = predict_if_crack(images)\n",
        "            # y_predict.append(predict)\n",
        "\n",
        "            # y_true = labels.cpu().numpy()\n",
        "            # y_true = y_true.reshape((len(y_true),1))\n",
        "            #y_true = y_true.flatten()\n",
        "\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            y_true.extend(labels.tolist())\n",
        "            predict = model(images)\n",
        "            y_hat = predict_if_crack(predict)\n",
        "            y_predict.extend(y_hat.cpu().tolist())\n"
      ],
      "metadata": {
        "id": "aQVf7a3CnlHj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_multiple_epochs(model, num_epochs, train_dataloader, test_dataloader, loss_function, optimizer,device,test_frequency=5):\n",
        "    \n",
        "    \"\"\"\n",
        "    Input: \n",
        "    model: Your network\n",
        "    num_epochs: Integer\n",
        "    train_data_loader: Dataloader defined using an instance of 'CEE498_Concrete_dataset' corresponding to the training set\n",
        "    test_dataloader: Dataloader defined using an instance of 'CEE498_Concrete_dataset' corresponding to the test set\n",
        "    loss_function,optimizer: self explanatory\n",
        "    device: cuda (0) or cpu\n",
        "    test_frequency: Integer: At what frequency do you want to evaluate performance on the test set\n",
        "    \n",
        "    Ouput:\n",
        "    model: Your model trainged after 'num_epochs' epochs\n",
        "    \"\"\"\n",
        "    for epoch in range(1,num_epochs+1):\n",
        "        print(\"Starting epoch number \" + str(epoch))\n",
        "        train_loss,model = train_classifier_one_epoch(train_dataloader, model, loss_function, optimizer,device)\n",
        "        print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n",
        "    return model"
      ],
      "metadata": {
        "id": "ihVatiyOe42O"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_1 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "print(resnet18_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "161b9ba5fe1e4a43aa093b7e9deb4e9f",
            "527f4dc76528447aa9145afa2cd9f6d0",
            "49d6e74f3022412b9b17710171a97472",
            "b6c9a8a382704df69ae28cf6acf97a88",
            "22a125466ed546cf842cd0929376ebde",
            "059b0f26e11a4f5dba3d3ef894c4f1d9",
            "9c841448ada4429ba778e294274d68ea",
            "698a29f8a8ea4fbcb23866f0d28f3995",
            "079f4028aeed4fe9aa9569e9d29436c4",
            "6a15c420b2c9409ba004a0224616e0b3",
            "0b779f1bdd7b458e808815542626ad73"
          ]
        },
        "id": "RA4zZ8-VfGF5",
        "outputId": "3608c249-8f29-418a-c698-5ae06236ed8a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "161b9ba5fe1e4a43aa093b7e9deb4e9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_requires_grad_to_false(model):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "    model: Network with requires_grad=True\n",
        "    Output:\n",
        "    model: Network with requires_grad=False\n",
        "    \"\"\"\n",
        "    #You code after this line\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "    return model"
      ],
      "metadata": {
        "id": "o4ddq0HwfL1g"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_1=set_requires_grad_to_false(resnet18_1)\n",
        "print(resnet18_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x35uNEqUfOwx",
        "outputId": "45c9b9fc-1455-45dd-f7f1-0be3bd2e6ed5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Implement the above in this cell\n",
        "resnet18_1.fc = nn.Sequential(nn.Linear(512, 4), nn.LogSoftmax())\n",
        "\n",
        "#Do not remove this\n",
        "resnet18_1.to(device)"
      ],
      "metadata": {
        "id": "sKxovOv1fSUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2472c3ef-b46c-4e5d-c028-84dfe255984c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=4, bias=True)\n",
              "    (1): LogSoftmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function=nn.CrossEntropyLoss()#Choose a loss function you wish to optimize in this excersise\n",
        "learning_rate=0.0001#Choose a learning rate\n",
        "optimizer=torch.optim.SGD(resnet18_1.parameters(), lr=learning_rate)#Choose an optimizer you wish\n",
        "number_of_epochs=15#Choose the number of epochs\n",
        "test_frequency=2 #(how often do you want to display performance on the test data)\n",
        "resnet18_1=train_multiple_epochs(resnet18_1, number_of_epochs, train_dataloader, test_dataloader, loss_function, optimizer,device,test_frequency)\n"
      ],
      "metadata": {
        "id": "vfnHmzFlfW-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b870966d-6f3f-4015-ccf6-60f7b95a8b94"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch number 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "Training progress within an epoch: 414it [00:12, 31.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 1 is 94.59964413195848\n",
            "Starting epoch number 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 33.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 2 is 15.478144401684403\n",
            "Starting epoch number 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 32.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 3 is 8.98856493551284\n",
            "Starting epoch number 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 33.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 4 is 6.238833989016712\n",
            "Starting epoch number 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 33.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 5 is 4.851642609573901\n",
            "Starting epoch number 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 34.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 6 is 3.93977307388559\n",
            "Starting epoch number 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 34.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 7 is 3.339437468908727\n",
            "Starting epoch number 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 34.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 8 is 2.9128513913601637\n",
            "Starting epoch number 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 34.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 9 is 2.582872357685119\n",
            "Starting epoch number 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 34.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 10 is 2.2947833677753806\n",
            "Starting epoch number 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 34.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 11 is 2.0538152211811393\n",
            "Starting epoch number 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 34.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 12 is 1.8828785957302898\n",
            "Starting epoch number 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 33.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 13 is 1.7589469028171152\n",
            "Starting epoch number 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 33.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 14 is 1.616011222358793\n",
            "Starting epoch number 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training progress within an epoch: 414it [00:12, 34.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for Training on Epoch 15 is 1.4916362650692463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = [94.59964413195848,15.478144401684403,8.98856493551284,\n",
        "        6.238833989016712,4.851642609573901,3.93977307388559,\n",
        "        3.339437468908727,2.9128513913601637,2.582872357685119,2.2947833677753806,2.0538152211811393,1.8828785957302898,\n",
        "        1.7589469028171152,1.616011222358793,1.4916362650692463]\n",
        "\n",
        "plt.plot(np.array(loss),marker='o')\n",
        "plt.title('Loss in training - Baseline')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.savefig('loss.png', dpi=300, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "7K0jWtEspz_Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "30515b29-4a7b-47d6-eaba-33ed81207290"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m0ruLhom_Mhp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}